{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fracture  Prediction performance : 10 fold cross-validation\n",
    "1. using  MLP\n",
    "2. Using hyperparameters assigned to each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "#warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read  Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data_one=\"C:/Progetti/option3_dataset_balanced/codice_14987.csv\"\n",
    "data_one=\"D:/Progetti/option3_dataset_balanced_withoutindex/evitabile_38144.csv\"\n",
    "df=read_csv(data_one)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extarction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.718e+04 1.010e+02 1.000e+00 2.000e+00 1.000e+00 1.000e+00 2.000e+00\n",
      " 1.000e+00 1.000e+00 4.000e+01 4.110e+02 1.560e+02 1.300e+01 1.600e+01\n",
      " 2.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 5.000e+00 0.000e+00\n",
      " 1.400e+01 3.500e+01 2.000e+00 1.100e+01 8.000e+01 1.000e+00 0.000e+00\n",
      " 1.400e+01 1.300e+01 4.200e+01 3.146e+04 1.000e+00 5.000e+00 8.000e+00\n",
      " 6.000e+00 0.000e+00 0.000e+00 5.000e+00 2.000e+00 5.000e+00 1.000e+00\n",
      " 1.000e+00 2.300e+01 7.000e+00 3.300e+01 3.260e+02 1.700e+01 0.000e+00\n",
      " 0.000e+00 2.000e+00 5.000e+01 2.100e+01 3.900e+01 1.700e+01 1.400e+01\n",
      " 6.000e+00 1.600e+01]\n",
      "[[0 0 0 0 0 0 0 0 0 1 2 2 0 0 0 0 1 2 4 5 1 4 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0]\n",
      " [1 4 0 1 1 1 1 0 1 0 2 2 0 1 0 0 1 2 4 5 2 3 0 0 1 1 0 0 0 0 1 0 0 0 0 0\n",
      "  1 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 0 0 0]\n",
      " [2 3 0 0 0 0 1 0 1 0 2 2 0 2 1 0 1 2 3 5 1 3 0 0 1 1 0 0 0 0 1 0 1 0 0 1\n",
      "  1 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 0]\n",
      " [3 3 0 0 0 0 0 0 1 0 2 2 1 0 0 0 1 2 4 5 1 4 0 0 0 1 1 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1]\n",
      " [4 5 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 2 3 5 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "array = df.values\n",
    "X = array[:,0:58]\n",
    "Y = array[:,58]\n",
    "\n",
    "# feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=58)\n",
    "fit = test.fit(X, Y)\n",
    "\n",
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "feature_score=np.around(fit.scores_)\n",
    "print(feature_score)\n",
    "features = fit.transform(X)\n",
    "\n",
    "# summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            features  pvalues  X2_score\n",
      "0              cleta  0.00000   77175.0\n",
      "31            mental  0.00000   31461.0\n",
      "10  n_farmaci_gruppo  0.00000     411.0\n",
      "46              resp  0.00000     326.0\n",
      "11             cod_1  0.00000     156.0\n",
      "1    cittad_psa_pfpm  0.00000     101.0\n",
      "25              artr  0.00000      80.0\n",
      "51              circ  0.00000      50.0\n",
      "30              glau  0.00000      42.0\n",
      "9       polpre2_farm  0.00000      40.0\n",
      "53             cuore  0.00000      39.0\n",
      "22          fratture  0.00000      35.0\n",
      "45              nerv  0.00000      33.0\n",
      "43             neopl  0.00000      23.0\n",
      "52              alim  0.00001      21.0\n",
      "47              musc  0.00005      17.0\n",
      "54              derm  0.00003      17.0\n",
      "57             sensi  0.00007      16.0\n",
      "13             cod_3  0.00007      16.0\n",
      "21          disabile  0.00014      14.0\n",
      "55             genit  0.00023      14.0\n",
      "28               ane  0.00021      14.0\n",
      "29              iper  0.00031      13.0\n",
      "12             cod_2  0.00035      13.0\n",
      "24              diab  0.00094      11.0\n",
      "34           demenza  0.00497       8.0\n",
      "44             blood  0.00939       7.0\n",
      "56          ormonali  0.01335       6.0\n",
      "35               cad  0.01460       6.0\n",
      "33           tiroide  0.02078       5.0\n",
      "40           fibratr  0.02511       5.0\n",
      "19         AFF_11BII  0.02670       5.0\n",
      "38          insufren  0.03029       5.0\n",
      "23             depre  0.20634       2.0\n",
      "3         n_notrauma  0.13557       2.0\n",
      "39           ipercol  0.21892       2.0\n",
      "50         endocrine  0.17802       2.0\n",
      "6                adi  0.11932       2.0\n",
      "14             cod_4  0.15489       2.0\n",
      "32            cancro  0.29043       1.0\n",
      "2              n_urg  0.45250       1.0\n",
      "4         n_ricoveri  0.32068       1.0\n",
      "5            maxchar  0.32616       1.0\n",
      "7           ese_redd  0.41429       1.0\n",
      "8           invalido  0.26988       1.0\n",
      "42             infec  0.32757       1.0\n",
      "41       femore_prec  0.44678       1.0\n",
      "26              park  0.25678       1.0\n",
      "16          STCIVSLP  0.76462       0.0\n",
      "48               uri  0.73437       0.0\n",
      "49             diges  0.53990       0.0\n",
      "27              epil  0.86064       0.0\n",
      "37             ictus  0.61039       0.0\n",
      "36               chf  0.84667       0.0\n",
      "15            TITGOD  0.98957       0.0\n",
      "17           ISTRSLP  0.92454       0.0\n",
      "20      tipologianew  0.80522       0.0\n",
      "18          CONDPSLP  0.71429       0.0\n"
     ]
    }
   ],
   "source": [
    "rownames = ['cleta','cittad_psa_pfpm','n_urg','n_notrauma','n_ricoveri','maxchar','adi','ese_redd','invalido','polpre2_farm',\n",
    "        'n_farmaci_gruppo','cod_1','cod_2','cod_3','cod_4','TITGOD','STCIVSLP','ISTRSLP','CONDPSLP','AFF_11BII','tipologianew',\n",
    "         'disabile','fratture','depre','diab','artr','park','epil','ane','iper','glau','mental','cancro','tiroide','demenza',\n",
    "         'cad','chf','ictus','insufren','ipercol','fibratr','femore_prec','infec','neopl','blood','nerv','resp','musc','uri',\n",
    "         'diges','endocrine','circ','alim','cuore','derm','genit','ormonali','sensi']\n",
    "features=pd.DataFrame(rownames) \n",
    "#print('Pvalues')\n",
    "pvalues=pd.DataFrame(fit.pvalues_).round(5) \n",
    "X2_score=pd.DataFrame(feature_score) \n",
    "feature_pvalue=pd.concat([features,pvalues,X2_score],axis=1,ignore_index=True)\n",
    "feature_pvalue.columns=['features','pvalues','X2_score']\n",
    "feature_pvalue=feature_pvalue.sort_values(by=['X2_score'],ascending=False)\n",
    "print(feature_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_33=df[['cleta','cittad_psa_pfpm','polpre2_farm',\n",
    "        'n_farmaci_gruppo','cod_1','cod_2','cod_3','AFF_11BII',\n",
    "         'disabile','fratture','diab','artr','ane','iper','glau','mental','tiroide','demenza',\n",
    "         'cad','insufren','fibratr','neopl','blood','nerv','resp','musc',\n",
    "         'circ','alim','cuore','derm','genit','ormonali','sensi','ricovero_evitabile']]\n",
    "\n",
    "print(df_33.shape)\n",
    "df_33.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Grid Search with cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df_33.values\n",
    "X = array[:,0:33]\n",
    "Y = array[:,33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train+validation set and test set\n",
    "X_trainval, X_test, y_trainval, Y_test = train_test_split(X, Y,test_size=0.20, random_state=7)\n",
    "\n",
    "# split train+validation set into training and validation set\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_trainval,y_trainval,test_size=0.30,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range    \n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,10,10),(50,100,50),(100,)], # (10,10,10) indicates 3 layers with 10 hiden units\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model: Training  set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model with cross validation\n",
    "grid = GridSearchCV(mlp, param_grid, refit = True, cv=10 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  fit  Model  on the  training  set \n",
    "grid.fit(X_train, Y_train)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters after tuning: {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "                            \n",
      "The model after hyper-parameter tuning: \n",
      "MLPClassifier(activation='tanh', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "best_params=grid.best_params_\n",
    "print('best parameters after tuning:',best_params)\n",
    "#print(grid.best_params_) \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print('                            ')\n",
    "print('The model after hyper-parameter tuning: ')\n",
    "print(grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model:Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on Validation set: 0.738394320043692\n"
     ]
    }
   ],
   "source": [
    "# evaluate the Model  on the validation set\n",
    "best_model=grid.best_estimator_\n",
    "score = best_model.score(X_valid, Y_valid)\n",
    "print('score on Validation set:',score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuild model on the combined training and validation set\n",
    "\n",
    "Training + Validation + best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpb=MLPClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.72\n",
      "1    0.72\n",
      "2    0.74\n",
      "3    0.73\n",
      "4    0.73\n",
      "5    0.74\n",
      "6    0.74\n",
      "7    0.74\n",
      "8    0.74\n",
      "9    0.74\n",
      "dtype: float64\n",
      "0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=3)\n",
    "cv_results = cross_val_score(mlpb, X_trainval, y_trainval, cv=kfold, scoring='accuracy') \n",
    "cv_results=pd.DataFrame([cv_results])\n",
    "cv=cv_results.mean().round(2)\n",
    "print(cv)\n",
    "print(np.round(cv.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting (build) the model on the combined training and validation sets\n",
    "mlpb.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model:Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute  model on the test set (prediction on test set)\n",
    "predictions = mlpb.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      3874\n",
      "           1       0.73      0.73      0.73      3755\n",
      "\n",
      "    accuracy                           0.74      7629\n",
      "   macro avg       0.74      0.74      0.74      7629\n",
      "weighted avg       0.74      0.74      0.74      7629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion Matrix:\n",
      "[[2875  999]\n",
      " [1014 2741]]\n",
      "Performanace results\n",
      "TPR: 0.73\n",
      "TNR: 0.74\n",
      "ACC: 0.74\n",
      "Precision: 0.73\n",
      "Recall: 0.73\n",
      "F1-Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = mlpb.predict(X_test) \n",
    "confusion=confusion_matrix(Y_test, predictions)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "    \n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)  \n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "Precision = TP/(TP+FP)\n",
    "Recall = TP/(TP+FN)\n",
    "F1_Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "print('confusion Matrix:')\n",
    "print(confusion)\n",
    "print('Performanace results')  \n",
    "print('TPR:',TPR.round(2))\n",
    "print('TNR:',TNR.round(2))\n",
    "print('ACC:',ACC.round(2))\n",
    "print('Precision:',Precision.round(2))\n",
    "print('Recall:',Recall.round(2))\n",
    "print('F1-Score:',F1_Score.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
